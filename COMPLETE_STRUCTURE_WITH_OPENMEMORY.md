# ğŸ§  Complete Local Stack with OpenMemory - Full Detailed Structure

## ğŸ“Š Enhanced System Architecture with OpenMemory

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACES                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ AnythingLLM UI   â”‚  â”‚   n8n UI         â”‚  â”‚  Todoist App     â”‚ â”‚
â”‚  â”‚ localhost:3001   â”‚  â”‚ localhost:5678   â”‚  â”‚  (Mobile/Web)    â”‚ â”‚
â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚                  â”‚ â”‚
â”‚  â”‚ - Chat           â”‚  â”‚ - Workflows      â”‚  â”‚ - Tasks          â”‚ â”‚
â”‚  â”‚ - Documents      â”‚  â”‚ - Monitoring     â”‚  â”‚ - Quick entry    â”‚ â”‚
â”‚  â”‚ - Agent tools    â”‚  â”‚ - Debugging      â”‚  â”‚ - Notifications  â”‚ â”‚
â”‚  â”‚ - Memory search  â”‚  â”‚ - Chat import    â”‚  â”‚                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â†“                      â†“                      â†“            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      APPLICATION LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ AnythingLLM (Container)                                       â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ RAG Engine (retrieves from Qdrant + OpenMemory)            â”‚  â”‚
â”‚  â”‚ â€¢ Custom Skills (JavaScript)                                  â”‚  â”‚
â”‚  â”‚   â”œâ”€ create-reminder.js                                       â”‚  â”‚
â”‚  â”‚   â”œâ”€ create-task.js                                           â”‚  â”‚
â”‚  â”‚   â”œâ”€ create-event.js                                          â”‚  â”‚
â”‚  â”‚   â”œâ”€ search-memory.js         (NEW - OpenMemory search)      â”‚  â”‚
â”‚  â”‚   â”œâ”€ store-memory.js          (NEW - Save to OpenMemory)     â”‚  â”‚
â”‚  â”‚   â””â”€ import-chat-history.js   (NEW - Import ChatGPT/Claude)  â”‚  â”‚
â”‚  â”‚ â€¢ MCP Client (connects to MCP server)                         â”‚  â”‚
â”‚  â”‚ â€¢ Vector Search Client (Qdrant + OpenMemory)                  â”‚  â”‚
â”‚  â”‚ â€¢ LLM Client (connects to Ollama)                             â”‚  â”‚
â”‚  â”‚ â€¢ Document Processor (20+ formats)                            â”‚  â”‚
â”‚  â”‚ â€¢ OpenMemory Client (stores conversations)                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                 â†“                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ n8n (Container)                                               â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ Workflow Engine                                             â”‚  â”‚
â”‚  â”‚ â€¢ Core Workflows:                                             â”‚  â”‚
â”‚  â”‚   â”œâ”€ create-reminder (webhook)                                â”‚  â”‚
â”‚  â”‚   â”œâ”€ create-task (webhook)                                    â”‚  â”‚
â”‚  â”‚   â”œâ”€ create-event (webhook)                                   â”‚  â”‚
â”‚  â”‚   â”œâ”€ fire-reminders (cron: */1 * * * *)                       â”‚  â”‚
â”‚  â”‚   â”œâ”€ daily-summary (cron: 0 7 * * *)                          â”‚  â”‚
â”‚  â”‚   â”œâ”€ todoist-sync (cron: */15 * * * *)                        â”‚  â”‚
â”‚  â”‚   â”œâ”€ google-calendar-sync (cron: */15 * * * *)                â”‚  â”‚
â”‚  â”‚   â”œâ”€ expand-recurring-tasks (cron: 0 0 * * *)                 â”‚  â”‚
â”‚  â”‚   â”œâ”€ watch-vault-files (file trigger: /vault)                 â”‚  â”‚
â”‚  â”‚   â”œâ”€ watch-documents (file trigger: /documents)               â”‚  â”‚
â”‚  â”‚   â””â”€ cleanup-old-data (cron: 0 3 * * *)                       â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ OpenMemory Workflows (NEW):                                 â”‚  â”‚
â”‚  â”‚   â”œâ”€ import-chatgpt-export (webhook/file trigger)             â”‚  â”‚
â”‚  â”‚   â”œâ”€ import-claude-export (webhook/file trigger)              â”‚  â”‚
â”‚  â”‚   â”œâ”€ import-gemini-export (webhook/file trigger)              â”‚  â”‚
â”‚  â”‚   â”œâ”€ store-chat-turn (webhook - called after each chat)       â”‚  â”‚
â”‚  â”‚   â”œâ”€ sync-memory-to-vault (cron: 0 */6 * * *)                 â”‚  â”‚
â”‚  â”‚   â””â”€ enrich-memories (cron: 0 2 * * *)                        â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ Node Types: 200+ built-in integrations                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                 â†“                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ MCP Server (Container)                                        â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ Database Tools (12 total):                                  â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_reminders_today()                                    â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_reminders_upcoming(days)                             â”‚  â”‚
â”‚  â”‚   â”œâ”€ search_reminders(query)                                  â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_events_today()                                       â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_events_upcoming(days)                                â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_tasks_by_status(status)                              â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_tasks_due_soon(days)                                 â”‚  â”‚
â”‚  â”‚   â”œâ”€ search_notes(query)                                      â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_recent_notes(limit)                                  â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_reminder_categories()                                â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_day_summary()                                        â”‚  â”‚
â”‚  â”‚   â””â”€ get_week_summary()                                       â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ Memory Tools (NEW - 5 total):                               â”‚  â”‚
â”‚  â”‚   â”œâ”€ search_memories(query, sector)                           â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_recent_memories(limit)                               â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_conversation_context(conversation_id)                â”‚  â”‚
â”‚  â”‚   â”œâ”€ get_memory_by_id(memory_id)                              â”‚  â”‚
â”‚  â”‚   â””â”€ get_related_memories(memory_id)                          â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ Connection: stdio (IPC)                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                 â†“                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ OpenMemory (Container) - Long-term AI Memory â­               â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ Memory Storage & Retrieval                                  â”‚  â”‚
â”‚  â”‚   â”œâ”€ Stores conversations from ChatGPT, Claude, Gemini        â”‚  â”‚
â”‚  â”‚   â”œâ”€ Stores current AnythingLLM conversations                 â”‚  â”‚
â”‚  â”‚   â”œâ”€ Auto-classifies into sectors                             â”‚  â”‚
â”‚  â”‚   â””â”€ Multi-dimensional embedding (2-3 sectors per memory)     â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ Memory Sectors:                                             â”‚  â”‚
â”‚  â”‚   â”œâ”€ semantic: Facts, concepts, knowledge                     â”‚  â”‚
â”‚  â”‚   â”œâ”€ episodic: Events, experiences, interactions              â”‚  â”‚
â”‚  â”‚   â”œâ”€ procedural: How-tos, workflows, processes                â”‚  â”‚
â”‚  â”‚   â”œâ”€ emotional: Sentiment, feelings, preferences              â”‚  â”‚
â”‚  â”‚   â””â”€ reflective: Insights, meta-cognition, patterns           â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ Search & Retrieval:                                         â”‚  â”‚
â”‚  â”‚   â”œâ”€ Composite scoring: 60% similarity + 20% salience         â”‚  â”‚
â”‚  â”‚   â”‚                      + 10% recency + 10% links            â”‚  â”‚
â”‚  â”‚   â”œâ”€ Cross-sector search                                      â”‚  â”‚
â”‚  â”‚   â”œâ”€ Temporal queries (memories from last week)               â”‚  â”‚
â”‚  â”‚   â””â”€ Relationship mapping (linked memories)                   â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ Import Formats Supported:                                   â”‚  â”‚
â”‚  â”‚   â”œâ”€ ChatGPT JSON export (conversations.json)                 â”‚  â”‚
â”‚  â”‚   â”œâ”€ Claude conversation export                               â”‚  â”‚
â”‚  â”‚   â”œâ”€ Gemini chat history                                      â”‚  â”‚
â”‚  â”‚   â”œâ”€ OpenAI API format                                        â”‚  â”‚
â”‚  â”‚   â””â”€ Generic JSON (with mapping)                              â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ Markdown Vault Sync (Optional):                             â”‚  â”‚
â”‚  â”‚   â””â”€ Mirrors memories to /memory_vault/*.md files             â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ API: REST (localhost:8080)                                  â”‚  â”‚
â”‚  â”‚ â€¢ Storage: PostgreSQL (metadata) + Qdrant (vectors)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI/ML LAYER                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Ollama (Container)                                            â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ LLM Models:                                                 â”‚  â”‚
â”‚  â”‚   â”œâ”€ llama3.2:3b (chat, 2GB RAM) - RECOMMENDED               â”‚  â”‚
â”‚  â”‚   â”œâ”€ llama3.1:8b (better quality, 5GB RAM)                    â”‚  â”‚
â”‚  â”‚   â”œâ”€ phi3:mini (fast, 2GB RAM)                                â”‚  â”‚
â”‚  â”‚   â””â”€ mistral:7b (good balance, 4GB RAM)                       â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ Embedding Models:                                           â”‚  â”‚
â”‚  â”‚   â”œâ”€ all-minilm (384 dims, fast) - RECOMMENDED               â”‚  â”‚
â”‚  â”‚   â”œâ”€ nomic-embed-text (768 dims, better quality)              â”‚  â”‚
â”‚  â”‚   â””â”€ mxbai-embed-large (1024 dims, best quality)              â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚ â€¢ API: REST (OpenAI compatible)                               â”‚  â”‚
â”‚  â”‚ â€¢ Port: 11434                                                 â”‚  â”‚
â”‚  â”‚ â€¢ Used by: AnythingLLM, n8n, OpenMemory                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA LAYER                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ PostgreSQL          â”‚  â”‚ Qdrant              â”‚  â”‚ Redis       â”‚â”‚
â”‚  â”‚ (Port 5434)         â”‚  â”‚ (Port 6333)         â”‚  â”‚ (Port 6379) â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚ Brainda DB:         â”‚  â”‚ Collections:        â”‚  â”‚ â€¢ n8n queue â”‚â”‚
â”‚  â”‚ â€¢ reminders         â”‚  â”‚  - knowledge_base   â”‚  â”‚ â€¢ Cache     â”‚â”‚
â”‚  â”‚ â€¢ tasks             â”‚  â”‚    (docs, notes)    â”‚  â”‚ â€¢ Sessions  â”‚â”‚
â”‚  â”‚ â€¢ events            â”‚  â”‚  - memories         â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ notes             â”‚  â”‚    (OpenMemory)     â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ documents         â”‚  â”‚                     â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ chunks            â”‚  â”‚ Vector dims: 384    â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ categories        â”‚  â”‚ Distance: Cosine    â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ file_sync         â”‚  â”‚                     â”‚  â”‚             â”‚â”‚
â”‚  â”‚                     â”‚  â”‚ Payloads:           â”‚  â”‚             â”‚â”‚
â”‚  â”‚ OpenMemory DB:      â”‚  â”‚ â€¢ user_id filter    â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ memories          â”‚  â”‚ â€¢ content_type      â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ memory_sectors    â”‚  â”‚ â€¢ sector            â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ conversations     â”‚  â”‚ â€¢ salience score    â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ memory_links      â”‚  â”‚ â€¢ temporal data     â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ embeddings        â”‚  â”‚                     â”‚  â”‚             â”‚â”‚
â”‚  â”‚                     â”‚  â”‚                     â”‚  â”‚             â”‚â”‚
â”‚  â”‚ n8n DB:             â”‚  â”‚                     â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ workflows         â”‚  â”‚                     â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ executions        â”‚  â”‚                     â”‚  â”‚             â”‚â”‚
â”‚  â”‚ â€¢ credentials       â”‚  â”‚                     â”‚  â”‚             â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STORAGE LAYER                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  /home/user/brainda/                                                â”‚
â”‚  â”œâ”€ vault/              (Markdown notes, auto-watched)              â”‚
â”‚  â”œâ”€ documents/          (PDFs, DOCX, auto-processed)                â”‚
â”‚  â”œâ”€ uploads/            (User uploads)                              â”‚
â”‚  â”œâ”€ memory_vault/       (OpenMemory markdown mirror) â­             â”‚
â”‚  â”œâ”€ chat_exports/       (ChatGPT/Claude JSON exports) â­            â”‚
â”‚  â”‚   â”œâ”€ chatgpt/                                                    â”‚
â”‚  â”‚   â”‚   â””â”€ conversations.json                                      â”‚
â”‚  â”‚   â”œâ”€ claude/                                                     â”‚
â”‚  â”‚   â”‚   â””â”€ export_2025-11-19.json                                  â”‚
â”‚  â”‚   â””â”€ gemini/                                                     â”‚
â”‚  â”‚       â””â”€ conversations_2025-11-19.json                           â”‚
â”‚  â”‚                                                                  â”‚
â”‚  â””â”€ Docker volumes:                                                 â”‚
â”‚      â”œâ”€ postgres_data/                                              â”‚
â”‚      â”œâ”€ qdrant_data/                                                â”‚
â”‚      â”œâ”€ redis_data/                                                 â”‚
â”‚      â”œâ”€ ollama_data/                                                â”‚
â”‚      â”œâ”€ anythingllm_data/                                           â”‚
â”‚      â”œâ”€ n8n_data/                                                   â”‚
â”‚      â””â”€ openmemory_data/                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Complete File System Structure with OpenMemory

```
/home/user/brainda/
â”‚
â”œâ”€â”€ ğŸ³ Docker Configuration
â”‚   â”œâ”€â”€ docker-compose.local-stack.yml    # Main compose (8 services)
â”‚   â”œâ”€â”€ .env.local-stack                   # Environment template
â”‚   â”œâ”€â”€ .env                               # Your config (git-ignored)
â”‚   â””â”€â”€ .dockerignore
â”‚
â”œâ”€â”€ ğŸ¤– MCP Server (Database + Memory Access)
â”‚   â””â”€â”€ mcp-server/
â”‚       â”œâ”€â”€ Dockerfile                     # Python 3.11 slim
â”‚       â”œâ”€â”€ requirements.txt               # mcp, asyncpg, httpx
â”‚       â””â”€â”€ server.py                      # 17 tools (12 DB + 5 memory)
â”‚
â”œâ”€â”€ ğŸ¨ AnythingLLM Custom Skills
â”‚   â””â”€â”€ anythingllm-custom-skills/
â”‚       â”œâ”€â”€ create-reminder.js             # Calls n8n webhook
â”‚       â”œâ”€â”€ create-task.js                 # Calls n8n webhook
â”‚       â”œâ”€â”€ create-event.js                # Calls n8n webhook
â”‚       â”œâ”€â”€ search-memory.js       â­ NEW # Search OpenMemory
â”‚       â”œâ”€â”€ store-memory.js        â­ NEW # Save to OpenMemory
â”‚       â””â”€â”€ import-chat-history.js â­ NEW # Import ChatGPT/Claude
â”‚
â”œâ”€â”€ ğŸ”„ n8n Workflows (JSON exports)
â”‚   â””â”€â”€ n8n-workflows/
â”‚       â”œâ”€â”€ Core Workflows:
â”‚       â”œâ”€â”€ 01-create-reminder.json        # POST /webhook/create-reminder
â”‚       â”œâ”€â”€ 02-create-task.json            # POST /webhook/create-task
â”‚       â”œâ”€â”€ 03-create-event.json           # POST /webhook/create-event
â”‚       â”œâ”€â”€ 04-fire-reminders.json         # Cron: */1 * * * *
â”‚       â”œâ”€â”€ 05-daily-summary.json          # Cron: 0 7 * * *
â”‚       â”œâ”€â”€ 06-todoist-sync.json           # Cron: */15 * * * *
â”‚       â”œâ”€â”€ 07-google-calendar-sync.json   # Cron: */15 * * * *
â”‚       â”œâ”€â”€ 08-expand-recurring-tasks.json # Cron: 0 0 * * *
â”‚       â”œâ”€â”€ 09-watch-vault.json            # File trigger: /vault
â”‚       â”œâ”€â”€ 10-watch-documents.json        # File trigger: /documents
â”‚       â”œâ”€â”€ 11-cleanup-old-data.json       # Cron: 0 3 * * *
â”‚       â”‚
â”‚       â”œâ”€â”€ OpenMemory Workflows: â­ NEW
â”‚       â”œâ”€â”€ 12-import-chatgpt-export.json  # Import ChatGPT JSON
â”‚       â”œâ”€â”€ 13-import-claude-export.json   # Import Claude conversations
â”‚       â”œâ”€â”€ 14-import-gemini-export.json   # Import Gemini chats
â”‚       â”œâ”€â”€ 15-store-chat-turn.json        # Save each chat message
â”‚       â”œâ”€â”€ 16-sync-memory-to-vault.json   # Export memories to MD
â”‚       â”œâ”€â”€ 17-enrich-memories.json        # Add salience, links
â”‚       â””â”€â”€ 18-search-and-summarize.json   # Memory-enhanced RAG
â”‚
â”œâ”€â”€ ğŸ“ Configuration Files
â”‚   â”œâ”€â”€ mcp-config.json                    # MCP server config
â”‚   â”œâ”€â”€ openmemory-config.json     â­ NEW # OpenMemory settings
â”‚   â””â”€â”€ tailscale/
â”‚       â””â”€â”€ config.json                    # Tailscale VPN
â”‚
â”œâ”€â”€ ğŸ—„ï¸ Database Migrations
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 001_initial_schema.sql
â”‚       â”œâ”€â”€ 002_add_reminders.sql
â”‚       â”œâ”€â”€ 003_add_tasks.sql
â”‚       â”œâ”€â”€ 004_add_events.sql
â”‚       â”œâ”€â”€ 005_add_categories.sql
â”‚       â”œâ”€â”€ 006_add_documents.sql
â”‚       â”œâ”€â”€ 007_add_todoist.sql
â”‚       â”œâ”€â”€ 008_add_indexes.sql
â”‚       â””â”€â”€ 009_openmemory_schema.sql â­ NEW # OpenMemory tables
â”‚
â”œâ”€â”€ ğŸ“š Data Directories (Mounted as Docker Volumes)
â”‚   â”œâ”€â”€ vault/                             # Markdown notes
â”‚   â”‚   â”œâ”€â”€ daily/
â”‚   â”‚   â”œâ”€â”€ projects/
â”‚   â”‚   â””â”€â”€ references/
â”‚   â”‚
â”‚   â”œâ”€â”€ documents/                         # PDFs, DOCX
â”‚   â”‚   â”œâ”€â”€ research/
â”‚   â”‚   â”œâ”€â”€ receipts/
â”‚   â”‚   â””â”€â”€ manuals/
â”‚   â”‚
â”‚   â”œâ”€â”€ uploads/                           # Manual uploads
â”‚   â”‚
â”‚   â”œâ”€â”€ memory_vault/              â­ NEW # OpenMemory markdown mirror
â”‚   â”‚   â”œâ”€â”€ semantic/                      # Factual knowledge
â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-11-19-python-concepts.md
â”‚   â”‚   â”‚   â””â”€â”€ 2025-11-20-docker-commands.md
â”‚   â”‚   â”œâ”€â”€ episodic/                      # Events & experiences
â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-11-19-project-discussion.md
â”‚   â”‚   â”‚   â””â”€â”€ 2025-11-20-debugging-session.md
â”‚   â”‚   â”œâ”€â”€ procedural/                    # How-tos
â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-11-19-setup-guide.md
â”‚   â”‚   â”‚   â””â”€â”€ 2025-11-20-workflow-creation.md
â”‚   â”‚   â”œâ”€â”€ emotional/                     # Preferences
â”‚   â”‚   â”‚   â””â”€â”€ 2025-11-19-user-preferences.md
â”‚   â”‚   â””â”€â”€ reflective/                    # Insights
â”‚   â”‚       â””â”€â”€ 2025-11-19-pattern-recognition.md
â”‚   â”‚
â”‚   â””â”€â”€ chat_exports/              â­ NEW # External chat imports
â”‚       â”œâ”€â”€ chatgpt/
â”‚       â”‚   â”œâ”€â”€ conversations.json         # Full ChatGPT export
â”‚       â”‚   â”œâ”€â”€ imported/                  # Processed flag files
â”‚       â”‚   â””â”€â”€ archive/                   # Backup of originals
â”‚       â”œâ”€â”€ claude/
â”‚       â”‚   â”œâ”€â”€ export_2025-11-19.json
â”‚       â”‚   â”œâ”€â”€ export_2025-11-18.json
â”‚       â”‚   â””â”€â”€ imported/
â”‚       â”œâ”€â”€ gemini/
â”‚       â”‚   â””â”€â”€ conversations_2025-11-19.json
â”‚       â””â”€â”€ custom/                        # Generic JSON imports
â”‚           â””â”€â”€ other_ai_chats.json
â”‚
â”œâ”€â”€ ğŸ“– Documentation
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ CLAUDE.md
â”‚   â”œâ”€â”€ LOCAL_STACK_SETUP.md
â”‚   â”œâ”€â”€ ARCHITECTURE_COMPARISON.md
â”‚   â”œâ”€â”€ TECHNICAL_FEATURES.md
â”‚   â”œâ”€â”€ DOCKER_SETUP.md
â”‚   â””â”€â”€ OPENMEMORY_GUIDE.md        â­ NEW # OpenMemory usage guide
â”‚
â”œâ”€â”€ ğŸ§ª Testing
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ stage_runner.sh
â”‚       â”œâ”€â”€ common.sh
â”‚       â”œâ”€â”€ stage*.sh
â”‚       â””â”€â”€ test_openmemory.sh     â­ NEW # Memory integration tests
â”‚
â””â”€â”€ ğŸ”§ Utility Scripts
    â””â”€â”€ scripts/
        â”œâ”€â”€ backup.sh
        â”œâ”€â”€ restore.sh
        â”œâ”€â”€ bulk_embed.py
        â”œâ”€â”€ export_workflows.sh
        â”œâ”€â”€ import_chatgpt.py      â­ NEW # ChatGPT JSON importer
        â”œâ”€â”€ import_claude.py       â­ NEW # Claude export importer
        â”œâ”€â”€ export_memories.py     â­ NEW # Export to markdown
        â””â”€â”€ enrich_memories.py     â­ NEW # Add salience scores
```

---

## ğŸ—„ï¸ Enhanced Database Schema with OpenMemory

### **OpenMemory Tables (New Database: `openmemory`)**

```sql
-- Memory Core Table
CREATE TABLE memories (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,                       -- User isolation
    content TEXT NOT NULL,                        -- The actual memory text
    memory_type TEXT DEFAULT 'explicit',          -- explicit, implicit, inferred
    source TEXT DEFAULT 'chat',                   -- chat, import, api, system
    source_reference TEXT,                        -- conversation_id, import_file, etc.
    salience_score FLOAT DEFAULT 0.5,            -- Importance: 0.0 - 1.0
    access_count INTEGER DEFAULT 0,               -- How many times retrieved
    last_accessed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    metadata JSONB                                -- Extra context
);

CREATE INDEX idx_memories_user ON memories(user_id);
CREATE INDEX idx_memories_salience ON memories(salience_score DESC);
CREATE INDEX idx_memories_source ON memories(source);
CREATE INDEX idx_memories_created ON memories(created_at DESC);

-- Memory Sectors (Multi-dimensional classification)
CREATE TABLE memory_sectors (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    memory_id UUID NOT NULL REFERENCES memories(id) ON DELETE CASCADE,
    sector TEXT NOT NULL,                         -- semantic, episodic, procedural, emotional, reflective
    confidence FLOAT DEFAULT 1.0,                 -- Classification confidence
    embedding_id TEXT,                            -- Qdrant point ID for this sector
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(memory_id, sector)
);

CREATE INDEX idx_sectors_memory ON memory_sectors(memory_id);
CREATE INDEX idx_sectors_type ON memory_sectors(sector);

-- Conversations (Groups related memories)
CREATE TABLE conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    title TEXT,
    source TEXT,                                  -- anythingllm, chatgpt, claude, gemini
    external_id TEXT,                             -- Original conversation ID
    started_at TIMESTAMP,
    ended_at TIMESTAMP,
    message_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    metadata JSONB
);

CREATE INDEX idx_conversations_user ON conversations(user_id);
CREATE INDEX idx_conversations_source ON conversations(source);
CREATE INDEX idx_conversations_external ON conversations(external_id);

-- Memory Links (Relationships between memories)
CREATE TABLE memory_links (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    from_memory_id UUID NOT NULL REFERENCES memories(id) ON DELETE CASCADE,
    to_memory_id UUID NOT NULL REFERENCES memories(id) ON DELETE CASCADE,
    link_type TEXT NOT NULL,                      -- similar, contradicts, elaborates, caused_by, etc.
    strength FLOAT DEFAULT 0.5,                   -- Link strength: 0.0 - 1.0
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(from_memory_id, to_memory_id, link_type)
);

CREATE INDEX idx_links_from ON memory_links(from_memory_id);
CREATE INDEX idx_links_to ON memory_links(to_memory_id);
CREATE INDEX idx_links_type ON memory_links(link_type);

-- Imported Chat Metadata (Track what's been imported)
CREATE TABLE imported_chats (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    source TEXT NOT NULL,                         -- chatgpt, claude, gemini
    file_path TEXT NOT NULL,
    file_hash TEXT NOT NULL,                      -- SHA-256 of file
    conversations_count INTEGER,
    memories_created INTEGER,
    imported_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(user_id, file_hash)                   -- Prevent duplicate imports
);

CREATE INDEX idx_imports_user ON imported_chats(user_id);
CREATE INDEX idx_imports_source ON imported_chats(source);
CREATE INDEX idx_imports_hash ON imported_chats(file_hash);
```

---

## ğŸ”· Enhanced Qdrant Collections with OpenMemory

### **Collection 1: `knowledge_base`** (Documents, Notes, Tasks)

```json
{
  "name": "knowledge_base",
  "config": {
    "params": {
      "vectors": {
        "size": 384,
        "distance": "Cosine"
      }
    }
  },
  "payload_schema": {
    "user_id": {"type": "keyword", "indexed": true},
    "content_type": {
      "type": "keyword",
      "values": ["note", "document_chunk", "reminder", "task", "event"]
    },
    "source_id": {"type": "keyword"},
    "title": {"type": "text"},
    "text": {"type": "text"},
    "created_at": {"type": "datetime"},
    "embedded_at": {"type": "datetime"}
  }
}
```

### **Collection 2: `memories`** (OpenMemory - Multi-Sector) â­ NEW

```json
{
  "name": "memories",
  "config": {
    "params": {
      "vectors": {
        "size": 384,
        "distance": "Cosine"
      }
    },
    "optimizers_config": {
      "indexing_threshold": 10000
    }
  },
  "payload_schema": {
    "user_id": {
      "type": "keyword",
      "indexed": true
    },
    "memory_id": {
      "type": "keyword",
      "indexed": true
    },
    "sector": {
      "type": "keyword",
      "indexed": true,
      "values": ["semantic", "episodic", "procedural", "emotional", "reflective"]
    },
    "content": {
      "type": "text"
    },
    "salience_score": {
      "type": "float",
      "indexed": true
    },
    "access_count": {
      "type": "integer"
    },
    "source": {
      "type": "keyword",
      "values": ["anythingllm", "chatgpt", "claude", "gemini", "api"]
    },
    "conversation_id": {
      "type": "keyword"
    },
    "created_at": {
      "type": "datetime",
      "indexed": true
    },
    "last_accessed_at": {
      "type": "datetime"
    },
    "tags": {
      "type": "keyword[]"
    },
    "entities": {
      "type": "keyword[]"
    },
    "linked_memory_ids": {
      "type": "keyword[]"
    }
  }
}
```

### **Example Memory Point (ChatGPT Import)**

```json
{
  "id": "chatgpt_conv123_turn5_semantic",
  "vector": [0.123, -0.456, ..., 0.789],
  "payload": {
    "user_id": "00000000-0000-0000-0000-000000000001",
    "memory_id": "memory_uuid-456",
    "sector": "semantic",
    "content": "Python list comprehensions are faster than for loops because they're optimized at the bytecode level",
    "salience_score": 0.85,
    "access_count": 0,
    "source": "chatgpt",
    "conversation_id": "chatgpt_conv123",
    "created_at": "2025-11-19T10:30:00Z",
    "tags": ["python", "performance", "programming"],
    "entities": ["Python", "list comprehension"],
    "linked_memory_ids": []
  }
}
```

---

## ğŸ”„ Complete Data Flow: ChatGPT Import to OpenMemory

### **Scenario: Import ChatGPT Export and Use in Current Conversations**

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 1: EXPORT FROM CHATGPT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

User actions:
1. Go to ChatGPT Settings â†’ Data Controls â†’ Export Data
2. Wait for email with download link
3. Download conversations.json
4. Save to: /home/user/brainda/chat_exports/chatgpt/conversations.json

File structure (conversations.json):
[
  {
    "id": "conv-abc123",
    "title": "Python optimization tips",
    "create_time": 1700000000,
    "update_time": 1700001000,
    "mapping": {
      "msg-1": {
        "message": {
          "author": {"role": "user"},
          "content": {"parts": ["How can I optimize Python code?"]}
        }
      },
      "msg-2": {
        "message": {
          "author": {"role": "assistant"},
          "content": {"parts": ["Here are 5 ways to optimize Python..."]}
        }
      }
    }
  },
  ... (100s more conversations)
]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 2: N8N DETECTS NEW FILE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Workflow: n8n-workflows/12-import-chatgpt-export.json

[File Trigger] - Watches /chat_exports/chatgpt/*.json
â”œâ”€ Triggers on: conversations.json
â””â”€ Mode: Poll every 5 minutes

[Hash Check] - Calculate SHA-256
â”œâ”€ Calculate file hash
â”œâ”€ Query: SELECT 1 FROM imported_chats WHERE file_hash = $1
â””â”€ If exists â†’ Skip (already imported)

[Read JSON File]
â”œâ”€ Read entire conversations.json
â”œâ”€ Parse JSON
â””â”€ Output: Array of conversation objects

[Function: Extract Conversations]
Code:
```javascript
const conversations = $input.item.json;
const extracted = [];

for (const conv of conversations) {
  const messages = [];

  // Parse mapping structure
  for (const [key, value] of Object.entries(conv.mapping)) {
    if (value.message) {
      messages.push({
        role: value.message.author.role,
        content: value.message.content.parts.join('\n'),
        timestamp: value.message.create_time
      });
    }
  }

  extracted.push({
    conversation_id: conv.id,
    title: conv.title,
    created_at: new Date(conv.create_time * 1000),
    messages: messages
  });
}

return extracted.map(c => ({json: c}));
```

Output: Array of parsed conversations

[Split into Batches] - Process 10 conversations at a time
â””â”€ Prevents timeout, memory issues

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 3: STORE IN OPENMEMORY DATABASE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[Loop: For Each Conversation]

  [PostgreSQL: Insert Conversation]
  SQL:
  INSERT INTO conversations (id, user_id, title, source, external_id, started_at, message_count)
  VALUES (gen_random_uuid(), $1, $2, 'chatgpt', $3, $4, $5)
  RETURNING id

  [Loop: For Each Message in Conversation]

    [Function: Extract Memory]
    Code:
    ```javascript
    const memory = {
      content: $json.content,
      user_id: $env.DEFAULT_USER_ID,
      memory_type: 'explicit',
      source: 'chatgpt',
      source_reference: $json.conversation_id,
      salience_score: 0.5  // Will be enriched later
    };
    return memory;
    ```

    [PostgreSQL: Insert Memory]
    SQL:
    INSERT INTO memories (user_id, content, source, source_reference, salience_score)
    VALUES ($1, $2, 'chatgpt', $3, 0.5)
    RETURNING id

    [Function: Classify Sectors]
    Code:
    ```javascript
    // Simple keyword-based classification (can use LLM for better results)
    const content = $json.content.toLowerCase();
    const sectors = [];

    // Semantic: Facts, definitions, explanations
    if (content.match(/is|are|means|definition|concept/)) {
      sectors.push('semantic');
    }

    // Episodic: Events, experiences, "I did", "We worked"
    if (content.match(/\b(i|we|you)\s+(did|made|worked|tried|fixed)/)) {
      sectors.push('episodic');
    }

    // Procedural: How-tos, steps, instructions
    if (content.match(/how to|step|first|then|next|install|configure/)) {
      sectors.push('procedural');
    }

    // Emotional: Preferences, feelings
    if (content.match(/prefer|like|hate|love|frustrat|enjoy/)) {
      sectors.push('emotional');
    }

    // Reflective: Insights, patterns, meta-cognition
    if (content.match(/realize|understand|pattern|insight|learn/)) {
      sectors.push('reflective');
    }

    // Default to semantic if nothing matched
    if (sectors.length === 0) sectors.push('semantic');

    return sectors.map(s => ({sector: s, memory_id: $json.memory_id}));
    ```

    [Loop: For Each Sector]

      [PostgreSQL: Insert Sector]
      SQL:
      INSERT INTO memory_sectors (memory_id, sector, confidence)
      VALUES ($1, $2, 0.8)
      RETURNING id

      [HTTP: Generate Embedding]
      POST http://ollama:11434/api/embeddings
      Body: {
        "model": "all-minilm",
        "prompt": $json.content
      }

      [HTTP: Store in Qdrant]
      PUT http://qdrant:6333/collections/memories/points
      Body: {
        "points": [{
          "id": "${memory_id}_${sector}",
          "vector": $json.embedding,
          "payload": {
            "user_id": $env.DEFAULT_USER_ID,
            "memory_id": $json.memory_id,
            "sector": $json.sector,
            "content": $json.content,
            "salience_score": 0.5,
            "source": "chatgpt",
            "conversation_id": $json.conversation_id,
            "created_at": $json.created_at
          }
        }]
      }

      [PostgreSQL: Update Sector with Embedding ID]
      UPDATE memory_sectors
      SET embedding_id = $1
      WHERE id = $2

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 4: TRACK IMPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[PostgreSQL: Record Import]
SQL:
INSERT INTO imported_chats (user_id, source, file_path, file_hash, conversations_count, memories_created)
VALUES ($1, 'chatgpt', '/chat_exports/chatgpt/conversations.json', $2, $3, $4)

[Move File to Archive]
mv /chat_exports/chatgpt/conversations.json
   /chat_exports/chatgpt/archive/conversations_2025-11-19.json

[Create Import Flag]
touch /chat_exports/chatgpt/imported/conversations.json.imported

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 5: ENRICH MEMORIES (Background Job)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Workflow: n8n-workflows/17-enrich-memories.json
Trigger: Daily at 2am

[PostgreSQL: Get Recent Memories]
SELECT * FROM memories
WHERE salience_score = 0.5  -- Default, not yet enriched
AND created_at > NOW() - INTERVAL '1 day'
LIMIT 100

[For Each Memory]

  [LLM: Calculate Salience]
  POST http://ollama:11434/api/generate
  Prompt:
  ```
  Rate the importance/salience of this memory from 0.0 to 1.0:

  Memory: "${content}"

  Consider:
  - Uniqueness (rare vs common knowledge)
  - Specificity (specific vs general)
  - Actionability (can be applied)
  - Emotional weight

  Return only a number between 0.0 and 1.0:
  ```

  [Update Salience Score]
  UPDATE memories SET salience_score = $1 WHERE id = $2

  [Update Qdrant Payload]
  POST http://qdrant:6333/collections/memories/points/payload
  Body: {
    "points": ["${memory_id}_semantic"],
    "payload": {
      "salience_score": $json.salience_score
    }
  }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 6: USE IN CURRENT CONVERSATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

User: "What did I learn about Python optimization?"

AnythingLLM Agent:
â”œâ”€ Detects query about past knowledge
â”œâ”€ Generates query embedding
â”‚
â”œâ”€ [Parallel Search]
â”‚  â”‚
â”‚  â”œâ”€ [Qdrant: Search Documents]
â”‚  â”‚  POST /collections/knowledge_base/points/search
â”‚  â”‚  {
â”‚  â”‚    "vector": [query_embedding],
â”‚  â”‚    "filter": {"must": [{"key": "user_id", "match": {"value": "..."}}]},
â”‚  â”‚    "limit": 3
â”‚  â”‚  }
â”‚  â”‚  Result: 0 matches (no recent documents about Python optimization)
â”‚  â”‚
â”‚  â””â”€ [Qdrant: Search Memories]
â”‚     POST /collections/memories/points/search
â”‚     {
â”‚       "vector": [query_embedding],
â”‚       "filter": {
â”‚         "must": [
â”‚           {"key": "user_id", "match": {"value": "..."}},
â”‚           {"key": "sector", "match": {"value": "semantic"}}
â”‚         ]
â”‚       },
â”‚       "limit": 5,
â”‚       "score_threshold": 0.6
â”‚     }
â”‚
â”‚     Results (sorted by composite score):
â”‚     1. "Python list comprehensions are faster..." (0.89, salience: 0.85)
â”‚     2. "Use generators for memory efficiency..." (0.87, salience: 0.75)
â”‚     3. "Numba JIT compilation speeds up loops..." (0.82, salience: 0.70)
â”‚
â”œâ”€ [Construct Context]
â”‚  Context from memories (ChatGPT import):
â”‚  ```
â”‚  Relevant past knowledge:
â”‚
â”‚  1. From conversation on 2024-05-15:
â”‚     "Python list comprehensions are faster than for loops because
â”‚      they're optimized at the bytecode level"
â”‚
â”‚  2. From conversation on 2024-06-20:
â”‚     "Use generators for memory efficiency when processing large
â”‚      datasets - they don't load everything into memory"
â”‚
â”‚  3. From conversation on 2024-07-10:
â”‚     "Numba JIT compilation can speed up numerical loops by 50-100x"
â”‚  ```
â”‚
â”œâ”€ [LLM Generation]
â”‚  POST http://ollama:11434/api/chat
â”‚  Model: llama3.2:3b
â”‚  Messages: [
â”‚    {role: "system", content: "You have access to user's past conversations..."},
â”‚    {role: "user", content: "What did I learn about Python optimization?"},
â”‚    {role: "assistant", content: [Generated with context]}
â”‚  ]
â”‚
â””â”€ Response:
   "Based on your previous conversations, you learned several Python
    optimization techniques:

    1. **List Comprehensions**: You discovered they're faster than
       traditional for loops due to bytecode-level optimizations.

    2. **Generators**: You learned to use generators for memory-efficient
       processing of large datasets.

    3. **Numba JIT**: You explored Numba for speeding up numerical
       computations by 50-100x.

    Would you like me to elaborate on any of these, or explore new
    optimization techniques?"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 7: STORE CURRENT CONVERSATION IN OPENMEMORY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

After each chat turn in AnythingLLM:

Workflow: n8n-workflows/15-store-chat-turn.json
Trigger: Webhook called by AnythingLLM after each message

[Webhook] POST /webhook/store-chat-turn
Body: {
  "user_message": "What did I learn about Python optimization?",
  "assistant_response": "Based on your previous conversations...",
  "conversation_id": "anythingllm_conv789",
  "user_id": "00000000-0000-0000-0000-000000000001"
}

[Insert User Message as Memory]
[Insert Assistant Response as Memory]
[Classify Sectors]
[Generate Embeddings]
[Store in Qdrant]

Now future queries can reference BOTH ChatGPT AND AnythingLLM conversations!
```

---

## ğŸ“‚ Chat Export Format Examples

### **ChatGPT Export Format**

```json
{
  "conversations.json": [
    {
      "id": "conv-abc123",
      "title": "Python optimization tips",
      "create_time": 1700000000,
      "update_time": 1700001000,
      "mapping": {
        "msg-uuid-1": {
          "id": "msg-uuid-1",
          "message": {
            "id": "msg-uuid-1",
            "author": {"role": "user"},
            "create_time": 1700000000,
            "content": {
              "content_type": "text",
              "parts": ["How can I optimize Python code?"]
            }
          }
        },
        "msg-uuid-2": {
          "id": "msg-uuid-2",
          "message": {
            "id": "msg-uuid-2",
            "author": {"role": "assistant"},
            "create_time": 1700000100,
            "content": {
              "content_type": "text",
              "parts": [
                "Here are 5 ways to optimize Python code:\n\n1. Use list comprehensions...\n2. Profile with cProfile...\n3. Use generators for large datasets...\n4. Leverage NumPy for numerical operations...\n5. Consider Cython for performance-critical code..."
              ]
            }
          }
        }
      }
    }
  ]
}
```

### **Claude Export Format**

```json
{
  "conversations": [
    {
      "uuid": "conv-xyz789",
      "name": "Docker optimization",
      "created_at": "2025-11-19T10:00:00.000Z",
      "updated_at": "2025-11-19T11:30:00.000Z",
      "chat_messages": [
        {
          "uuid": "msg-1",
          "text": "How can I optimize Docker builds?",
          "sender": "human",
          "created_at": "2025-11-19T10:00:00.000Z"
        },
        {
          "uuid": "msg-2",
          "text": "Here are key strategies for optimizing Docker builds:\n\n1. **Multi-stage builds**: Separate build and runtime stages...\n2. **Layer caching**: Order Dockerfile commands by change frequency...\n3. **`.dockerignore`**: Exclude unnecessary files...",
          "sender": "assistant",
          "created_at": "2025-11-19T10:01:00.000Z"
        }
      ]
    }
  ]
}
```

### **Gemini Export Format**

```json
{
  "conversations": [
    {
      "conversation_id": "conv-gemini-123",
      "conversation": {
        "id": "conv-gemini-123",
        "create_time": "2025-11-19T09:00:00Z",
        "update_time": "2025-11-19T09:30:00Z"
      },
      "messages": [
        {
          "author": "user",
          "text": "Explain quantum computing",
          "create_time": "2025-11-19T09:00:00Z"
        },
        {
          "author": "model",
          "text": "Quantum computing leverages quantum mechanics principles like superposition and entanglement...",
          "create_time": "2025-11-19T09:00:30Z"
        }
      ]
    }
  ]
}
```

---

## ğŸ”„ Complete Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXTERNAL CHAT SERVICES                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ChatGPT (conversations.json export)                       â”‚
â”‚ â€¢ Claude (JSON export)                                      â”‚
â”‚ â€¢ Gemini (conversation history)                             â”‚
â”‚ â€¢ Other AI services                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ Export JSON files
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ /chat_exports/                                              â”‚
â”‚ â”œâ”€ chatgpt/conversations.json                               â”‚
â”‚ â”œâ”€ claude/export_2025-11-19.json                            â”‚
â”‚ â””â”€ gemini/conversations.json                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ File trigger (every 5 min)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ n8n Workflow: Import Chat History                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Detect new file                                          â”‚
â”‚ 2. Check hash (avoid duplicates)                            â”‚
â”‚ 3. Parse JSON (format-specific parser)                      â”‚
â”‚ 4. Extract conversations & messages                         â”‚
â”‚ 5. For each message:                                        â”‚
â”‚    â”œâ”€ Insert to PostgreSQL (memories table)                 â”‚
â”‚    â”œâ”€ Classify sectors (semantic/episodic/etc)              â”‚
â”‚    â”œâ”€ Generate embedding (Ollama)                           â”‚
â”‚    â””â”€ Store in Qdrant (memories collection)                 â”‚
â”‚ 6. Track import (imported_chats table)                      â”‚
â”‚ 7. Move file to archive                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ Stored in
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL (openmemory DB)     â”‚ Qdrant (memories)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ memories (content, metadata) â”‚ â€¢ Multi-sector vectors     â”‚
â”‚ â€¢ memory_sectors (classification) â”‚ â€¢ User filtering       â”‚
â”‚ â€¢ conversations (groups)       â”‚ â€¢ Salience scoring         â”‚
â”‚ â€¢ memory_links (relationships) â”‚ â€¢ Temporal indexing        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ Retrieved during
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Current AnythingLLM Conversation                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User: "What did I learn about Python?"                      â”‚
â”‚   â†“                                                          â”‚
â”‚ AnythingLLM Agent:                                          â”‚
â”‚ â”œâ”€ Generate query embedding                                 â”‚
â”‚ â”œâ”€ Search Qdrant (knowledge_base + memories)                â”‚
â”‚ â”‚  â”œâ”€ Documents: 0 results                                  â”‚
â”‚ â”‚  â””â”€ Memories: 5 results (from ChatGPT import)             â”‚
â”‚ â”œâ”€ Retrieve memory content from PostgreSQL                  â”‚
â”‚ â”œâ”€ Construct context with citations                         â”‚
â”‚ â””â”€ Generate response with LLM                               â”‚
â”‚   â†“                                                          â”‚
â”‚ Response: "Based on your conversation on 2024-05-15..."     â”‚
â”‚   â†“                                                          â”‚
â”‚ n8n Workflow: Store Current Turn                            â”‚
â”‚ â”œâ”€ Save user question as memory                             â”‚
â”‚ â”œâ”€ Save assistant response as memory                        â”‚
â”‚ â”œâ”€ Link to current conversation                             â”‚
â”‚ â””â”€ Embed and store in Qdrant                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ Optionally
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Memory Vault Sync (n8n workflow, every 6 hours)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Query recent memories from PostgreSQL                    â”‚
â”‚ 2. Group by sector                                          â”‚
â”‚ 3. Format as markdown                                       â”‚
â”‚ 4. Write to /memory_vault/{sector}/{date}-{title}.md        â”‚
â”‚ 5. Create YAML frontmatter with metadata                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Key Benefits

### **All Your AI Conversations in ONE Place**
- âœ… ChatGPT, Claude, Gemini, and AnythingLLM conversations all searchable
- âœ… No more context switching between different AI services
- âœ… Build on past knowledge across all platforms

### **Smart Memory Organization**
- âœ… Multi-sector classification (semantic, episodic, procedural, emotional, reflective)
- âœ… Salience scoring (important memories surface first)
- âœ… Memory linking (related concepts connected automatically)
- âœ… Temporal queries ("what did I learn last month?")

### **100% Local & Private**
- âœ… All data stays on your machine
- âœ… No cloud dependencies
- âœ… Complete control over your knowledge base
- âœ… Works offline

### **Future-Proof**
- âœ… Import from any AI service (extensible parsers)
- âœ… Export to markdown (portable, version controlled)
- âœ… PostgreSQL + Qdrant (industry-standard storage)
- âœ… Open-source stack (no vendor lock-in)

---

## ğŸš€ Next Steps

1. **Set up the stack**: Follow `LOCAL_STACK_SETUP.md`
2. **Export your conversations**: Download from ChatGPT, Claude, Gemini
3. **Drop files in `/chat_exports/`**: n8n automatically processes
4. **Start chatting**: Ask "What have I learned about X?" and watch the magic!

---

**This is your complete, detailed structure with OpenMemory fully integrated for a unified AI knowledge base!**
